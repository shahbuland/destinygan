I'm not entirely sure how far I got with this code but I don't think it was complete. It was basically a copy of other contrastive learning code I've written but with two image encoders. The idea was that one head would work on gun images and the other on the smaller icons. This way an icon could be chosen that matched a sampled gun by the same process CLIP + Dall-E rank and select generated images based on text (except in this case the prompt is another image).
